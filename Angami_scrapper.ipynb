{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUn5HMjtwK36Eb2a5NKD8m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mashedpotatoagain/YouBible_Scapper/blob/main/Angami_scrapper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QVNqJZSeIEU"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import time\n",
        "\n",
        "listA=[]\n",
        "listE=[]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scrapeChapter(book, chapter_no):\n",
        "    chapter_urlsA = [f\"https://www.bible.com/bible/338/{book}.{i}.ANBRBSI\" for i in range(1,chapter_no)]\n",
        "    chapter_urlsE = [f\"https://www.bible.com/bible/12/{book}.{i}.EASY\" for i in range(1,chapter_no)]\n",
        "\n",
        "    ####################Scrap the dialect########################\n",
        "    for idx, page in enumerate(chapter_urlsA):\n",
        "        page_to_scrape = requests.get(page)\n",
        "        soup_A = BeautifulSoup(page_to_scrape.text, 'html.parser')\n",
        "        verses = soup_A.find_all(\"span\", class_ = \"ChapterContent_verse__57FIw\")\n",
        "\n",
        "        for verse in verses:\n",
        "            passage = verse.find_all(\"span\", class_ = \"ChapterContent_content__RrUqA\")\n",
        "            var = [verse_line.get_text(strip=True, separator=' ') for verse_line in passage]\n",
        "\n",
        "            label = verse.find(\"span\", class_ = \"ChapterContent_label__R2PLt\")\n",
        "\n",
        "            ########################3\n",
        "            try:\n",
        "                int(label.get_text())   #The get_text is important since label is just the tag/html element type\n",
        "                allow = True\n",
        "            except:\n",
        "                allow = False\n",
        "            #######################3\n",
        "\n",
        "            if verse.find(\"span\", class_ = \"ChapterContent_label__R2PLt\") and allow == True:\n",
        "                line =\" \".join(var)\n",
        "                listA.append(line+\"\\n\")\n",
        "            else:\n",
        "                line = line+\" \".join(var)\n",
        "                listA.pop()\n",
        "                listA.append(line+\"\\n\")\n",
        "\n",
        "\n",
        "    ######################Scrape the english yeah#########################\n",
        "    for idx, page in enumerate(chapter_urlsE):\n",
        "        page_to_scrape = requests.get(page)\n",
        "        soup_A = BeautifulSoup(page_to_scrape.text, 'html.parser')\n",
        "        verses = soup_A.find_all(\"span\", class_ = \"ChapterContent_verse__57FIw\")\n",
        "\n",
        "        for verse in verses:\n",
        "            passage = verse.find_all(\"span\", class_ = \"ChapterContent_content__RrUqA\")\n",
        "            var = [verse_line.get_text(strip=True, separator=' ') for verse_line in passage]\n",
        "\n",
        "            label = verse.find(\"span\", class_ = \"ChapterContent_label__R2PLt\")\n",
        "\n",
        "            ################################\n",
        "            try:\n",
        "                int(label.get_text())\n",
        "                allow = True\n",
        "            except:\n",
        "                allow = False\n",
        "            ###############################\n",
        "\n",
        "            if verse.find(\"span\", class_ = \"ChapterContent_label__R2PLt\") and allow == True:\n",
        "                line =\" \".join(var)\n",
        "                listE.append(line+\"\\n\")\n",
        "            else:\n",
        "                line = line+\" \".join(var)\n",
        "                listE.pop()\n",
        "                listE.append(line+\"\\n\")"
      ],
      "metadata": {
        "id": "m-Ii7HLTeWJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books = [\"GEN\", \"EXO\", \"LEV\", \"NUM\", \"DEU\", \"JOS\", \"JDG\", \"RUT\", \"1SA\", \"2SA\", \"1KI\", \"2KI\", \"1CH\", \"2CH\", \"EZR\", \"NEH\", \"EST\", \"JOB\"]\n",
        "chapters = [50, 40, 27, 36, 34, 24, 21, 4, 31, 24, 22, 25, 29,36, 10, 13, 10, 42]\n",
        "\n",
        "\n",
        "for idx, book in enumerate(books):\n",
        "    scrapeChapter(book, chapters[idx])\n",
        "    time.sleep(100)\n",
        "\n",
        "\n",
        "with open(\"Angami.txt\", \"w\") as f:\n",
        "    f.writelines(listA)\n",
        "    f.close()\n",
        "\n",
        "with open(\"English.txt\", \"w\") as f:\n",
        "    f.writelines(listE)\n",
        "    f.close()\n",
        "print(\"Done\")"
      ],
      "metadata": {
        "id": "Tkn5vAyxePY6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}